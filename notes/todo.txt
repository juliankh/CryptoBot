TODO:

-misc
    (after 2023-06-16 2:50pm)...
    -check
        -any exceptions at all: grep -i exception *kraken_bridge_orderbook*2023-06-16_14*
        -direct instrument bridge
            -status update with null connection_id was persisted ok: grep "Latest OrderBook Snapshot was generated" direct_kraken_bridge_orderbook*2023-06-16_14*
        -direct orderbook bridge
            -ever get snapshots after the initial one: grep "Received OrderBook Snapshot" direct_kraken_bridge_orderbook*2023-06-16_14*
            -any req_id that doesn't match: grep "Request ID returned" direct_kraken_bridge_orderbook*2023-06-16_14*
            -reconnections -- how often because websocket closed or because no data received within some time limit
    -compare xchage vs direct orderbook bridges
        -how often have checksum mismatches
        -frequency of socket drops

    -if the snapshot age log msgs show that a time delay develops (presumably because consumption of orderbook data is slower then the rate at which data is sent by the exchange), then look into optimizing the checksum algorithm
    -make log4j logs rollover to new log files every 24 hours and keep the past 10 log versions
    -auto-restart processes after restarting computer
    -see how to make the assembled jar smaller (without unnecessary libs) so that the build runs faster
    -if there is no use case to use jms, then remove jms-related code
    -DirectKrakenInstrumentBridgeDriver: replace with a cron job that regularly calls the REST API and updates the db
-ML
    -admin
        -ensure ML uses gpu processors
    -model variations
        -no derived features vs derived features
        -training data range: 10 min, 30 min, 60 min, 120 min
        -prediction scope: 5 min, 10 min, 15 min, 30 min
        -orderbook depth: 500, 200, 100, 50, 20, 10
    -derived features
        -1st order derived
            -area under curve
                -absolute area under curve
                -% diff in area under curve between bids and asks
                -for different depths (500, 200, 100, 50, 20, 10)
            -time
                -minute of hour
                -hour of day
                -hour and minute of day
            -spread size (absolute or relative to midprice)
        -2nd order derived
            -% change for some feature vs some previous time (1 min ago, 2 min ago, 5 min ago, 10 min ago, 30 min ago, 60 min ago)
    -questions
        -if a feature has no bearing on prediction accuracy, will NN learn to ignore it?  How important is it to omit that feature?